{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projet scrapping \n",
    "Site : trustpilot.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va importer les biblio nécessaires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisatiion du scrapping \n",
    "Nous allons srapper les les 50 prémière pages du site "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer une liste vide qui va stocker nos commentaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentaire=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on boucle sur l'url pour avoir les 50 pages \n",
    "for j in range(2,50):\n",
    "    url =\"https://fr.trustpilot.com/review/www.shein.com?page=\"+str(j)\n",
    "    \n",
    "    # on récupère chaque url par la méthode du get \n",
    "    reponse =requests.get(url)\n",
    "    \n",
    "    # on le stock dans un soup pour recupérer le text\n",
    "    soup = BeautifulSoup(reponse.text,'html')\n",
    "    \n",
    "    # cette etape nous permet de recup la structure de site pour prendre les elements qui nous interresse \n",
    "    soup_page=soup.find_all('article', {'class':'review'})\n",
    "    for t in soup_page:\n",
    "        try:\n",
    "            \n",
    "            commentaire.append((t.find('p', {'class':'review-content__text'})).text)\n",
    "        except:\n",
    "            commentaire.append(\"nan\")\n",
    "            pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va vérifier le nombre de commentraire récupéré "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre de commentaire est : 960\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"le nombre de commentaire est :\",len(commentaire))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va stocker notre liste dans un dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(commentaire)),\n",
    "               columns =['commentaire'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentaire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>\\n                Jamais recu , pas terrible\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>\\n                nous avons commandé le 7 nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>\\n                Je suis en colère !! J'ai pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>\\n                1ère commande et très très s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>\\n                J’avais passer ma commande l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>\\n                Je suis une grande acheteuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>\\n                Je suis mitigé car côté prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>\\n                Commande faite le 5 novembre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>\\n                Bonjour j’attend mon colis d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>\\n                Bonjour, j’ai plus de nouvel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           commentaire\n",
       "951  \\n                Jamais recu , pas terrible\\n...\n",
       "544  \\n                nous avons commandé le 7 nov...\n",
       "224  \\n                Je suis en colère !! J'ai pa...\n",
       "191  \\n                1ère commande et très très s...\n",
       "631  \\n                J’avais passer ma commande l...\n",
       "579  \\n                Je suis une grande acheteuse...\n",
       "635  \\n                Je suis mitigé car côté prod...\n",
       "472  \\n                Commande faite le 5 novembre...\n",
       "278  \\n                Bonjour j’attend mon colis d...\n",
       "524  \\n                Bonjour, j’ai plus de nouvel..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Affichage du dataframe \n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de donnée n'est pas propre mais dans la continuité pour du nlp bcp de petites fonctions nous permettront de néttoyer ce jeu et le rendre utilisable pour pouvoir ensuite appliquer des méthodes comme :\n",
    "La segmentation \n",
    "La tokenisation \n",
    "ou encore le lemmantisation et bien d'autre "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
